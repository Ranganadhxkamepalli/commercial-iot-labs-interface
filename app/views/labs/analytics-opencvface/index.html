<div class="row wrapper border-bottom white-bg page-heading">
  <div class="col-lg-10">
    <h2>Face detection using OpenCV</h2>
    <ol class="breadcrumb">
      <li>
        <a href="index.html">Home</a>
      </li>
      <li>
        <a>Labs</a>
      </li>
      <li>
        <strong>Video Analytics</strong>
      </li>
      <li class="active">
        <strong>Face detection using OpenCV</strong>
      </li>
    </ol>
  </div>
</div>

<div class="wrapper wrapper-content animated fadeInRight" ng-controller="CodeEditorCtrl">
  <div class="row">
    <div class="col-lg-12">

      <div ibox title="Objectives">
        <div content-block name="opencv_motion-objectives" message="Complete Objectives">
          <h2 class="labHidden"></h2>
          <h5>Lab Overview</h5>
          <p>We have done motion detection in our previous module. We will find number of faces associated with that motion
          </p>
          <ul>
            <li>Instantiate a cascade classifier for the face</li>
            <li>We will identify the faces using Haar cascade method</li>
            <li>Finally we will count the number of faces in the frame</li>
            <li>Show the video</li>
            <li>Release resources</li>
          </ul>
        </div>
      </div>

      <div ibox title="Overview of the Facial Recogition Sample">

        <div content-block name="opencv_motion-newfile" message="Create a new Python script and load the required modules">
          <h5>The first step is load the Haar-like features classifer cascade file, which is a file create through machine learning to contain the esstential features of a face. In OpenCV, you can detect different types of objects by changing the classifier file.</h5>

          <p>Download the haar cascade file, named <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades" target="_new">haarcascade_frontalface_default.xml </a> face, and save it into the same directory as your python script.</p>
          <p>Create a new Python file named <b>face_detect.py</b></p>
          <p>Paste the following line</p>
          <ui-codemirror ui-codemirror-opts="editorOptions"><pre class="brush:jscript;">import cv2</pre></ui-codemirror>
        </div>

        <div content-block name="opencv_motion-newfile" message="Load the facial classifier and open a connection to the camera">
          <p>You will need to open the classifier file and a connection to the video camera.</p>
          <ui-codemirror ui-codemirror-opts="editorOptions"><pre class="brush:jscript;"># Create a Haar-like feature cascade classifier object
faceCascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

# Set the camera to the first camera detected by the NUC
cap = cv2.VideoCapture(0)</pre></ui-codemirror>
        </div>


<div ibox title="The Facial Detector's main loop">
  <div content-block name="opencv_motion-vid_display" message="The Facial Detector's main loop">

  <p>This code performs a number of steps:</p>
  <ol>
    <li>It captures the current frame</li>
    <li>Converts it to grayscale for a faster comparison</li>
    <li>Sends the grayscale frame to the facial recogition detector</li>
    <li>The detector returns an array of coordinates of a box with a (x,y,w,h)</li>
    <li>Draws a rectangle around the face</li>
    <li>Shows the frame</li>
    <li>If the user hits the 'Esc' key the program will exit<li>
  </ol>

  <ui-codemirror ui-codemirror-opts="editorOptions"><pre class="brush:jscript;">while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    # begin face cascade
    faces = faceCascade.detectMultiScale(
        gray,
        scaleFactor=1.25,
        minNeighbors=5,
        minSize=(30, 30),
    )

    for (x, y, w, h) in faces:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Display the resulting frame
    cv2.imshow('Video', frame)

    # If the user presses the 'q' key then quit the program
    if cv2.waitKey(1) & 0xFF == 27:
       break</pre></ui-codemirror>
    </div>

    <div ibox title="Here is the final solution">
      <div content-block name="opencv_motion-newfile" message="Here is the final solution">
        Here is the final code for face counting including motion detection sample we did in previous example. Here we first we detect the motion, then we try to find faces in the scene.
          <ui-codemirror ui-codemirror-opts="editorOptions"><pre class="brush:jscript;">import cv2

            cv2.namedWindow('frame')
            cv2.namedWindow('dist')

            # the classifier that will be used in the cascade
            faceCascade = cv2.CascadeClassifier('haar_face.xml')

            #capture video stream from camera source. 0 refers to first camera, 1 referes to 2nd and so on.
            cap = cv2.VideoCapture(0)


            triggered = False
            sdThresh = 10
            font = cv2.FONT_HERSHEY_SIMPLEX

            def distMap(frame1, frame2):
                """outputs pythagorean distance between two frames"""
                frame1_32 = np.float32(frame1)
                frame2_32 = np.float32(frame2)
                diff32 = frame1_32 - frame2_32
                norm32 = np.sqrt(diff32[:,:,0]**2 + diff32[:,:,1]**2 + diff32[:,:,2]**2)/np.sqrt(255**2 + 255**2 + 255**2)
                dist = np.uint8(norm32*255)
                return dist

            _, frame1 = cap.read()
            _, frame2 = cap.read()
            facecount = 0
            while(True):
                _, frame3 = cap.read()
                rows, cols, _ = np.shape(frame3)
                cv2.imshow('dist', frame3)
                dist = distMap(frame1, frame3)

                frame1 = frame2
                frame2 = frame3

                # apply Gaussian smoothing
                mod = cv2.GaussianBlur(dist, (9,9), 0)

                # apply thresholding
                _, thresh = cv2.threshold(mod, 100, 255, 0)

                # calculate st dev test
                _, stDev = cv2.meanStdDev(mod)

                cv2.imshow('dist', mod)
                cv2.putText(frame2, "Standard Deviation - {}".format(round(stDev[0][0],0)), (70, 70), font, 1, (255, 0, 255), 1, cv2.LINE_AA)


                if stDev > sdThresh:
                        # the cascade is implemented in grayscale mode
                        gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)

                        # begin face cascade
                        faces = faceCascade.detectMultiScale(
                            gray,
                            scaleFactor=2,
                            minSize=(20, 20)
                        )
                        facecount = 0
                        # draw a rectangle over detected faces
                        for (x, y, w, h) in faces:
                            facecount = facecount + 1
                            cv2.rectangle(frame2, (x, y), (x+w, y+h), (0, 255, 0), 1)
                        cv2.putText(frame2, "No of faces {}".format(facecount), (50, 50), font, 1, (0, 0, 255), 1, cv2.LINE_AA)
                else:
                        if facecount > 0:
                                print("Face count:")
                                print(facecount)
                                facecount = 0
                cv2.imshow('frame', frame2)

                if cv2.waitKey(1) & 0xFF == 27:
                    break

            cap.release()
            cv2.destroyAllWindows()
</pre></ui-codemirror>
              </div>
            </div>

        <div ibox title="References">
          <ul>
              <li>
                  <p><a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html" target="_blank">OpenCV-Python Tutorials</a></p></li><li>
                  <p><a href="https://pythonprogramming.net/loading-images-python-opencv-tutorial/" target="_blank">Opencv with Python</a></p>
              </li>
          </ul>
        </div>


      </div>
  </div>

        </div>
    </div>
</div>
